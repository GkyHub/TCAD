\relax 
\citation{simonyan2014very}
\citation{simonyan2014very}
\citation{han2015learning}
\citation{Rastegari2016XNOR}
\citation{zhang2015optimizing}
\citation{du2015shidiannao}
\citation{he2015deep}
\citation{simonyan2014very}
\citation{qiu2016going}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{sec:intro}{{I}{1}}
\citation{krizhevsky2012imagenet}
\citation{simonyan2014very}
\citation{he2015deep}
\citation{long2015fully}
\citation{krizhevsky2012imagenet}
\citation{zeiler2014visualizing}
\citation{simonyan2014very}
\citation{iandola2016squeezenet}
\citation{zhang2015optimizing}
\citation{zhang2015optimizing}
\citation{gokhale2014240}
\citation{qiu2016going}
\citation{du2015shidiannao}
\citation{sim2016deep}
\citation{chen2016eyeriss}
\@writefile{toc}{\contentsline {section}{\numberline {II}Preliminary of CNN}{2}}
\newlabel{sec:prime}{{II}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Related Work}{2}}
\newlabel{sec:related_work}{{III}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}State-of-the-art CNN Model}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}CNN Accelerator}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Flow Description}{2}}
\newlabel{sec:flow}{{IV}{2}}
\citation{qiu2016going}
\citation{qiu2016going}
\citation{qiu2016going}
\citation{bosi1999reconfigurable}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Typical layers in CNN: (a) Convolutional layer; (b) Fully-Connected layer (dense matrix multiplication); (c) Non-linear layer with Rectified Linear Unit; (d) Max-pooling layer with 2$\times $2 kernel.\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:primer}{{1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A practical CNN model for face alignment. For each layer, the kernel size, output channel number and nonlinearity type is given.\relax }}{3}}
\newlabel{fig:face_align_net}{{2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Design flow from CNN model to hardware acceleration\relax }}{3}}
\newlabel{fig:flow}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Data Quantization}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Hardware Architecture}{3}}
\citation{szegedy2014going}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Data quantization flow\nobreakspace  {}\cite  {qiu2016going}\relax }}{4}}
\newlabel{fig:quantization}{{4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Overall architecture of Angel-Eye\relax }}{4}}
\newlabel{fig:arch}{{5}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Structure of a single PE\relax }}{4}}
\newlabel{fig:pe}{{6}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Structure of Controller\relax }}{4}}
\newlabel{fig:controller}{{7}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Instruction Set and Compiler}{4}}
\newlabel{sec:ins_comp}{{\unhbox \voidb@x \hbox {IV-C}}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Experiment}{4}}
\newlabel{sec:experiment}{{V}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Data Quantization Result}{4}}
\citation{chakradhar2010dynamically}
\citation{gokhale2014240}
\citation{zhang2015optimizing}
\citation{qiu2016going}
\citation{qiu2016going}
\citation{gokhale2014240}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Hardware Parameter and Resource utilization\relax }}{5}}
\newlabel{tab:resource}{{I}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Five point face alignment result. Red points: floating-point network result. Green points: 8-bit fixed point network result.\relax }}{5}}
\newlabel{fig:face_align_res}{{8}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Exploration of different data quantization strategies with state-of-the-art CNNs.\relax }}{5}}
\newlabel{tab:quantization}{{II}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Hardware Performance}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Performance comparison of Angel-Eye on XC7Z045 with other FPGA designs\cite  {qiu2016going}\relax }}{5}}
\newlabel{tab:perf7045}{{III}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Performance comparison of Angel-Eye on XC7Z202 with TK1 on 5-point face alignment task\relax }}{5}}
\newlabel{tab:perf7020}{{IV}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{5}}
\newlabel{sec:conclusion}{{VI}{5}}
\bibstyle{IEEEtran}
\bibdata{ref}
\bibcite{simonyan2014very}{1}
\bibcite{han2015learning}{2}
\bibcite{Rastegari2016XNOR}{3}
\bibcite{zhang2015optimizing}{4}
\bibcite{du2015shidiannao}{5}
\bibcite{he2015deep}{6}
\bibcite{qiu2016going}{7}
\bibcite{krizhevsky2012imagenet}{8}
\bibcite{long2015fully}{9}
\bibcite{zeiler2014visualizing}{10}
\bibcite{iandola2016squeezenet}{11}
\bibcite{gokhale2014240}{12}
\bibcite{sim2016deep}{13}
\bibcite{chen2016eyeriss}{14}
\bibcite{bosi1999reconfigurable}{15}
\bibcite{szegedy2014going}{16}
\bibcite{chakradhar2010dynamically}{17}
